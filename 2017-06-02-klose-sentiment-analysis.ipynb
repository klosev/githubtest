{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis und Natural Language Processing Übung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "**Führen Sie eine Sentiment Analyse mit Hilfe des Natural Language Toolkits und des Naive Bayes Verfahrens durch. Verwenden Sie dafür den *twitter_samples* Datensatz des NLTK.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def create_word_features(words):\n",
    "    useful_words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    my_dict = dict({(word, True) for word in useful_words})\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hinweis: Der Twitter Datensatz verwendet 2 JSON-Dateien, die jeweils die positiven oder negativen Tweets enthalten. `Python twitter_samples.strings('negative_tweets.json')` liefert beispielsweise einen Array aller negativen Tweets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_samples.fileids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle negativen Tweets sammeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strings = twitter_samples.strings('negative_tweets.json')\n",
    "neg_reviews = []\n",
    "for string in strings:\n",
    "    neg_reviews.append((create_word_features(string), \"negative\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle positiven Tweets sammeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strings = twitter_samples.strings('positive_tweets.json')\n",
    "pos_reviews = []\n",
    "for string in strings:\n",
    "    pos_reviews.append((create_word_features(string), \"positive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_reviews))\n",
    "print(len(pos_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jeweils 5.000 positive/negative Tweets. Zur Erstellung des Trainingsdatensatzes verwenden wir jeweils 3.750 Tweets, den Rest für den Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = neg_reviews[:3750] + pos_reviews[:3750]\n",
    "test_set = neg_reviews[3750:] + pos_reviews[3750:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen des Klassifikators und trainieren mit dem Testdatensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.03999999999999\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(100*nltk.classify.util.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erhalten eine Genauigkeit von 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "**Validieren Sie Ihre Ergebnisse mit Hilfe von jeweils einem positiven und einem negativen Tweet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positiver Tweet:\n",
    "> The screen is gorgeous on the #OnePlus5 , it doesn't seem like a 1080P panel, really amazed by the quality\n",
    "\n",
    "Negativer Tweet:\n",
    "> I don't like the phone at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "positiver_tweet = \"The screen is gorgeous on the #OnePlus5 , it doesn't seem like a 1080P panel, really amazed by the quality\"\n",
    "negativer_tweet = \"I don't like the phone at all\"\n",
    "\n",
    "positiver_tweet = word_tokenize(positiver_tweet)\n",
    "positiver_tweet = create_word_features(positiver_tweet)\n",
    "\n",
    "negativer_tweet = word_tokenize(negativer_tweet)\n",
    "negativer_tweet = create_word_features(negativer_tweet)\n",
    "\n",
    "print(classifier.classify(positiver_tweet))\n",
    "print(classifier.classify(negativer_tweet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
