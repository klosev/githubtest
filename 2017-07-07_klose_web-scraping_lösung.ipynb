{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungen zu Web-Scraping mit BeautifulSoup\n",
    "\n",
    "## Aufgabe 1 - Theorie\n",
    "\n",
    "Beantworten sie bitte folgende Fragen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Was ist Web-Scraping?\n",
    "2. Was ist beim Scrapen erlaubt?\n",
    "3. Finden Sie noch andere Anwendungsbeipspiele?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afg. 1.1:\n",
    "\n",
    "Web Scraping ist die automatische Extraktion von Daten in einem Format, das man leicht für Analysen und weitere Bearbeitungen nutzen kann.\n",
    "\n",
    "Afg. 1.2:\n",
    "\n",
    "Daten dürfen von fremden Webseiten geholt werden, solange sich die Nutzung im Rahmen einer normalen Auswertung der Datenbank hält und die berechtigten Interessen des anderen nicht unzumutbar beeinträchtigt werden.\n",
    "\n",
    "Afg. 1.3:\n",
    "\n",
    "* Suchmaschinen, Webmining\n",
    "* Ersatz von Webservices\n",
    "* Erweitertes Browsen\n",
    "* Remixing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Anwendung\n",
    "\n",
    "Besuchen Sie zunächst folgende [Seite](http://econpy.pythonanywhere.com/ex/001.html) und sammeln Sie diese Daten in einem   `Dataframe`.\n",
    "\n",
    "Zum Einstieg erstmal nur die Daten der ersten angezeigten Webseite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page = requests.get('http://econpy.pythonanywhere.com/ex/001.html')\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "all_buyers = soup.find_all(\"div\", attrs={\"title\": \"buyer-name\"})\n",
    "all_prices = soup.find_all(\"span\", attrs={\"class\": \"item-price\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buyer = []\n",
    "\n",
    "for a in all_buyers:\n",
    "    buyers = a.string.strip()\n",
    "    buyer.append(buyers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "\n",
    "for a in all_prices:\n",
    "    prices = a.string.strip()\n",
    "    price.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Käufer</th>\n",
       "      <th>Preis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carson Busses</td>\n",
       "      <td>$29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earl E. Byrd</td>\n",
       "      <td>$8.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patty Cakes</td>\n",
       "      <td>$15.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Derri Anne Connecticut</td>\n",
       "      <td>$19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moe Dess</td>\n",
       "      <td>$19.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Käufer   Preis\n",
       "0           Carson Busses  $29.95\n",
       "1            Earl E. Byrd   $8.37\n",
       "2             Patty Cakes  $15.26\n",
       "3  Derri Anne Connecticut  $19.25\n",
       "4                Moe Dess  $19.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df = pd.DataFrame(data={'Käufer':buyer,'Preis':price})\n",
    "info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und nun probieren Sie sich daran, auch sämtliche Daten der anderen 4 Seiten zu holen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = ['http://econpy.pythonanywhere.com/ex/002.html', \n",
    "       'http://econpy.pythonanywhere.com/ex/003.html', \n",
    "       'http://econpy.pythonanywhere.com/ex/004.html', \n",
    "       'http://econpy.pythonanywhere.com/ex/005.html']\n",
    "\n",
    "for pg in url:\n",
    "    page = requests.get(pg)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    all_buyers= soup.find_all(\"div\", attrs={\"title\": \"buyer-name\"})\n",
    "    all_prices= soup.find_all(\"span\", attrs={\"class\": \"item-price\"})\n",
    "    \n",
    "    for a in all_buyers:\n",
    "        buyers = a.string.strip()\n",
    "        buyer.append(buyers)\n",
    "    for a in all_prices:\n",
    "        prices = a.string.strip()\n",
    "        price.append(prices)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Käufer</th>\n",
       "      <th>Preis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Missy Perriad</td>\n",
       "      <td>$15.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Carolina Rice</td>\n",
       "      <td>$28.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Anna Septic</td>\n",
       "      <td>$19.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Cass Tigate</td>\n",
       "      <td>$25.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Val Voline</td>\n",
       "      <td>$26.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Käufer   Preis\n",
       "175  Missy Perriad  $15.60\n",
       "176  Carolina Rice  $28.12\n",
       "177    Anna Septic  $19.97\n",
       "178    Cass Tigate  $25.70\n",
       "179     Val Voline  $26.28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.DataFrame(data={'Käufer':buyer,'Preis':price})\n",
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
